# Multi-Objective Neuro Evolution

<a href="#"><img src="https://raw.githubusercontent.com/dwyl/repo-badges/master/highresPNGs/build-passing.png" height="25"></a> <a href="https://trello.com/neurov"><img src="https://d2k1ftgv7pobq7.cloudfront.net/meta/u/res/images/brand-assets/Logos/0099ec3754bf473d2bbf317204ab6fea/trello-logo-blue.png" height="25"></a>

## Abstract

In this variant, We seek performance of our model(: Neuro-evolution) on **Transfer Learning**. We used famous Caltech-256 dataset and divided ten classes in two buckets - Source (eiffel-tower, tennis-ball, elk, swan, centipede) and Target(windmill, bowling-ball, horse, duck, snake). Transfer Learning's presence was proven statistically with a low p-value.

In our core model, we implement a **memetic algorithm**, in that, we are training neural networks using **evolutionary algorithms** and occasionally apply **back-propagation** on cluster-heads.
We used **NEAT** techniques to realise Neural Network and combined it with **NSGA-II** to implement Genetic algorithm.

## Contributors

1. Swapnil Sharma
2. Aditya Pimparkar
3. Atul Kumar Sinha
4. Kunal Gupta
5. Raghav Khandelwal

